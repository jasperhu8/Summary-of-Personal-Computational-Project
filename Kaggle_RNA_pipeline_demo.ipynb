{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460d98d7",
   "metadata": {},
   "source": [
    "# RNA Folding Pipeline: YAML Conversion, Readable Data Loader, and Model Ensembling\n",
    "\n",
    "This notebook demonstrates three reusable components extracted and refactored from my Kaggle pipeline work:\n",
    "\n",
    "1. **YAML conversion** – turn raw RNA sequences into per-target YAML configs for downstream inference (Boltz-1 / Protenix).\n",
    "2. **Readable data loader** – standardize raw CSV into a clean, schema-checked DataFrame for batch processing.\n",
    "3. **Two-model ensemble** – wrap *Boltz-1* and *Protenix* predictors with a unified interface and combine outputs (mean / rank-average).\n",
    "\n",
    "> Note: The actual model inference steps are mocked with placeholder functions so the notebook is self-contained. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd13e5",
   "metadata": {},
   "source": [
    "## 1. YAML Conversion Utility\n",
    "\n",
    "Given a raw table of targets and sequences (e.g., from `train.csv` or `submission_template.csv`), we **emit one YAML file per target**.\n",
    "\n",
    "**Output schema** (minimal for inference):\n",
    "```yaml\n",
    "id: <sequence_id>\n",
    "sequence: <ACGU...>\n",
    "constraints: []\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b260ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def to_yaml_block(seq_id: str, seq: str) -> str:\n",
    "    \"\"\"\n",
    "    Minimal YAML config for model inference (per target).\n",
    "    \"\"\"\n",
    "    # Defensive clean-up to ensure only valid characters (ACGU) — adjust if other tokens are expected\n",
    "    clean_seq = re.sub(r'[^ACGU]', '', seq.upper())\n",
    "    return f\"id: {seq_id}\\nsequence: {clean_seq}\\nconstraints: []\\n\"\n",
    "\n",
    "def write_yaml_files(df: pd.DataFrame, id_col: str, seq_col: str, out_dir: str) -> None:\n",
    "    out = Path(out_dir)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    bad_rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        sid = str(row[id_col]).strip()\n",
    "        seq = str(row[seq_col]).strip()\n",
    "        if not sid or not seq:\n",
    "            bad_rows.append(i)\n",
    "            continue\n",
    "        yaml_text = to_yaml_block(sid, seq)\n",
    "        (out / f\"{sid}.yaml\").write_text(yaml_text)\n",
    "    if bad_rows:\n",
    "        print(f\"[WARN] Skipped {len(bad_rows)} rows with missing id/sequence: {bad_rows[:5]}{'...' if len(bad_rows)>5 else ''}\")\n",
    "    print(f\"[OK] Wrote YAML files to: {out.resolve()}\")\n",
    "\n",
    "# --- demo input (replace with your actual CSV) ---\n",
    "demo = pd.DataFrame({\n",
    "    \"target_id\": [\"T001\", \"T002\", \"T003\"],\n",
    "    \"sequence\":  [\"ACGUACGU\", \"ACGU-UU\", \"NNACGU\"]\n",
    "})\n",
    "\n",
    "write_yaml_files(demo, id_col=\"target_id\", seq_col=\"sequence\", out_dir=\"/mnt/data/inputs_prediction\")\n",
    "!ls -la /mnt/data/inputs_prediction | head -n 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf215c9e",
   "metadata": {},
   "source": [
    "## 2. Readable Data Loader\n",
    "\n",
    "Standardize input CSV to a **validated, tidy** DataFrame to minimize surprises downstream.\n",
    "\n",
    "- Required columns: `target_id`, `sequence`\n",
    "- Optional columns: anything else (kept and passed through)\n",
    "- Validation: non-empty `target_id`/`sequence`, legal tokens (A/C/G/U) with auto-clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e259b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "REQUIRED = [\"target_id\", \"sequence\"]\n",
    "\n",
    "def load_readable_csv(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    missing = [c for c in REQUIRED if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "    # normalize\n",
    "    df[\"target_id\"] = df[\"target_id\"].astype(str).str.strip()\n",
    "    df[\"sequence\"] = df[\"sequence\"].astype(str).str.upper().str.replace(r\"[^ACGU]\", \"\", regex=True)\n",
    "    # drop bad rows\n",
    "    df = df[(df[\"target_id\"]!=\"\") & (df[\"sequence\"]!=\"\")]\n",
    "    df = df.drop_duplicates(subset=[\"target_id\"])\n",
    "    return df\n",
    "\n",
    "# --- demo: write a quick CSV and reload ---\n",
    "demo_csv = \"/mnt/data/demo_sequences.csv\"\n",
    "pd.DataFrame({\n",
    "    \"target_id\": [\"T001\",\"T002\",\"T003\",\"T003\"],\n",
    "    \"sequence\":  [\"ACGU-ACGU\",\"acguNN\",\"\", \"ACGU\"]\n",
    "}).to_csv(demo_csv, index=False)\n",
    "\n",
    "clean_df = load_readable_csv(demo_csv)\n",
    "display(clean_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707a5e7",
   "metadata": {},
   "source": [
    "## 3. Two-Model Inference Wrappers and Ensembling\n",
    "\n",
    "We define a light abstraction for predictors:\n",
    "\n",
    "```python\n",
    "class Predictor:\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:  # returns columns: target_id, score\n",
    "        ...\n",
    "```\n",
    "\n",
    "Replace the mock implementations with your actual **Boltz-1** and **Protenix** calls. Then we offer two ensemble strategies:\n",
    "- **Mean ensemble:** arithmetic mean of model scores\n",
    "- **Rank-average ensemble:** average of normalized ranks (robust when score scales differ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Predictor:\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Boltz1Predictor(Predictor):\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # TODO: replace with real Boltz-1 inference reading from YAML/inputs_prediction\n",
    "        # Mock: score = length * 0.7 + random noise\n",
    "        rng = np.random.default_rng(42)\n",
    "        scores = df[\"sequence\"].str.len() * 0.7 + rng.normal(0, 0.3, size=len(df))\n",
    "        return pd.DataFrame({\"target_id\": df[\"target_id\"].values, \"boltz1_score\": scores})\n",
    "\n",
    "class ProtenixPredictor(Predictor):\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # TODO: replace with real Protenix inference\n",
    "        rng = np.random.default_rng(123)\n",
    "        scores = df[\"sequence\"].str.len() * 0.5 + rng.normal(0, 0.4, size=len(df))\n",
    "        return pd.DataFrame({\"target_id\": df[\"target_id\"].values, \"protenix_score\": scores})\n",
    "\n",
    "def mean_ensemble(df_scores: pd.DataFrame) -> pd.Series:\n",
    "    score_cols = [c for c in df_scores.columns if c.endswith(\"_score\")]\n",
    "    return df_scores[score_cols].mean(axis=1)\n",
    "\n",
    "def rank_average_ensemble(df_scores: pd.DataFrame) -> pd.Series:\n",
    "    score_cols = [c for c in df_scores.columns if c.endswith(\"_score\")]\n",
    "    ranks = df_scores[score_cols].rank(method=\"average\")\n",
    "    norm = (ranks - ranks.min()) / (ranks.max() - ranks.min() + 1e-9)\n",
    "    return norm.mean(axis=1)\n",
    "\n",
    "# --- demo using clean_df from previous cell ---\n",
    "boltz = Boltz1Predictor().predict(clean_df)\n",
    "prot  = ProtenixPredictor().predict(clean_df)\n",
    "\n",
    "joined = clean_df[[\"target_id\"]].merge(boltz, on=\"target_id\").merge(prot, on=\"target_id\")\n",
    "joined[\"score_mean\"] = mean_ensemble(joined[[\"boltz1_score\",\"protenix_score\"]])\n",
    "joined[\"score_rankavg\"] = rank_average_ensemble(joined[[\"boltz1_score\",\"protenix_score\"]])\n",
    "display(joined)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
